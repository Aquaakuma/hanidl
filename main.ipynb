{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cefdde17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import json\n",
    "import time\n",
    "import aiohttp\n",
    "import aiofiles\n",
    "import os\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List, Optional\n",
    "from bs4 import BeautifulSoup\n",
    "import cloudscraper\n",
    "from tqdm.notebook import tqdm\n",
    "from tqdm import tqdm as sync_tqdm  # ä¿ç•™åŒæ­¥è¿›åº¦æ¡\n",
    "import requests\n",
    "\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DownloadLink:\n",
    "    \"\"\"è§†é¢‘æ ¼å¼æ•°æ®ç±»\"\"\"\n",
    "    download_url: str   # è§†é¢‘ä¸‹è½½é“¾æ¥\n",
    "    suffix: str         # è§†é¢‘åç¼€/æ ¼å¼ï¼ˆå¦‚mp4, flvï¼‰\n",
    "    clarity: int        # è§†é¢‘æ¸…æ™°åº¦ï¼ˆæ•´æ•°ï¼Œå¦‚720, 1080ï¼‰\n",
    "\n",
    "@dataclass\n",
    "class Video:\n",
    "    \"\"\"è§†é¢‘æ•°æ®ç±»\"\"\"\n",
    "    title: str                   # è§†é¢‘æ ‡é¢˜\n",
    "    url: str                     # è§†é¢‘åŸå§‹é“¾æ¥\n",
    "    sources: List[DownloadLink] = field(default_factory=list)  # è§†é¢‘æ ¼å¼åˆ—è¡¨\n",
    "    \n",
    "    def add_download_link(self, DownloadLink):\n",
    "       self.sources.append(DownloadLink)\n",
    "    \n",
    "    def get_best_quality(self) -> Optional[DownloadLink]:\n",
    "        \"\"\"è·å–æœ€é«˜æ¸…æ™°åº¦çš„è§†é¢‘æ ¼å¼\"\"\"\n",
    "        return self.sources[0]\n",
    "\n",
    "    def download(self, path: str, retries: int = 3):\n",
    "        \"\"\"åŒæ­¥ä¸‹è½½æ–¹æ³•\"\"\"\n",
    "        if not self.sources[0]:\n",
    "            print(f\"æœªæ‰¾åˆ°ä¸‹è½½æº\")\n",
    "            return\n",
    "            \n",
    "        return self._sync_download(path, self.sources[0], retries)\n",
    "    \n",
    "    async def download_async(self, path: str, retries: int = 3, position: int = 0):\n",
    "        \"\"\"å¼‚æ­¥ä¸‹è½½æ–¹æ³•ï¼Œå¢åŠ ä½ç½®å‚æ•°\"\"\"     \n",
    "        if not self.sources:\n",
    "            print(f\"è§†é¢‘ {self.title} æœªæ‰¾åˆ°ä¸‹è½½æº\")\n",
    "            return\n",
    "            \n",
    "        return await self._async_download(path, self.sources[0], retries, position)\n",
    "\n",
    "    def _sync_download(self, path: str, source: DownloadLink, retries: int):\n",
    "        \"\"\"åŒæ­¥ä¸‹è½½å®ç°\"\"\"\n",
    "        target_folder = path\n",
    "        os.makedirs(target_folder, exist_ok=True)\n",
    "        file_name = f\"{self.title}.{source.suffix}\"\n",
    "        full_path = os.path.join(target_folder, file_name)\n",
    "        \n",
    "        for attempt in range(retries):\n",
    "            try:\n",
    "                response = requests.get(\n",
    "                    source.download_url, \n",
    "                    stream=True, \n",
    "                    timeout=(10, 60)  # è¿æ¥è¶…æ—¶10ç§’ï¼Œè¯»å–è¶…æ—¶60ç§’\n",
    "                )\n",
    "                response.raise_for_status()\n",
    "                \n",
    "                total_size = int(response.headers.get('content-length', 0))\n",
    "                progress_bar = sync_tqdm(\n",
    "                    total=total_size, \n",
    "                    unit='B', \n",
    "                    unit_scale=True,\n",
    "                    desc=f\"ä¸‹è½½ {file_name}\",\n",
    "                    unit_divisor=1024\n",
    "                )\n",
    "                \n",
    "                with open(full_path, 'wb') as file:\n",
    "                    for chunk in response.iter_content(chunk_size=8192):\n",
    "                        if chunk:\n",
    "                            file.write(chunk)\n",
    "                            progress_bar.update(len(chunk))\n",
    "                \n",
    "                progress_bar.close()\n",
    "                print(f\"ä¸‹è½½å®Œæˆ: {full_path}\")\n",
    "                return\n",
    "                \n",
    "            except Exception as e:\n",
    "                if attempt < retries - 1:\n",
    "                    print(f\"ä¸‹è½½å¤±è´¥ ({attempt+1}/{retries}), é‡è¯•ä¸­...: {str(e)}\")\n",
    "                    time.sleep(2 ** attempt)  # æŒ‡æ•°é€€é¿\n",
    "                else:\n",
    "                    print(f\"ä¸‹è½½å¤±è´¥ ({attempt+1}/{retries}): {str(e)}\")\n",
    "                    return\n",
    "    \n",
    "    async def _async_download(self, path: str, source: DownloadLink, retries: int, position: int = 0):\n",
    "        \"\"\"å¢å¼ºç‰ˆæ–­ç‚¹ç»­ä¼ ä¸‹è½½ï¼ˆå¤„ç†Accept-Ranges:bytesä½†ç»­ä¼ å¤±è´¥çš„æƒ…å†µï¼‰\"\"\"\n",
    "        target_folder = path\n",
    "        os.makedirs(target_folder, exist_ok=True)\n",
    "        file_name = f\"{self.title}.{source.suffix}\"\n",
    "        full_path = os.path.join(target_folder, file_name)\n",
    "        temp_path = full_path + \".part\"\n",
    "        \n",
    "        # ä¿®å¤1: ä¸‹è½½å‰æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å®Œæˆ\n",
    "        if os.path.exists(full_path):\n",
    "            existing_size = os.path.getsize(full_path)\n",
    "            # å°è¯•è·å–æœåŠ¡å™¨æ–‡ä»¶å¤§å°è¿›è¡ŒéªŒè¯\n",
    "            async with aiohttp.ClientSession() as session:\n",
    "                try:\n",
    "                    async with session.head(\n",
    "                        source.download_url,\n",
    "                        timeout=aiohttp.ClientTimeout(total=5)\n",
    "                    ) as head_response:\n",
    "                        head_response.raise_for_status()\n",
    "                        total_size = int(head_response.headers.get('content-length', 0))\n",
    "                        \n",
    "                        # æ–‡ä»¶å·²å­˜åœ¨ä¸”å¤§å°åŒ¹é…\n",
    "                        if total_size > 0 and existing_size == total_size:\n",
    "                            tqdm.write(f\"æ–‡ä»¶å·²å­˜åœ¨: {file_name}\")\n",
    "                            return {\n",
    "                                \"success\": True,\n",
    "                                \"file_name\": file_name,\n",
    "                                \"file_size\": existing_size,\n",
    "                                \"message\": f\"æ–‡ä»¶å·²å­˜åœ¨: {file_name}\"\n",
    "                            }\n",
    "                except Exception:\n",
    "                    # æ— æ³•éªŒè¯æœåŠ¡å™¨æ–‡ä»¶å¤§å°ï¼Œä½†æœ¬åœ°æ–‡ä»¶å­˜åœ¨\n",
    "                    tqdm.write(f\"æ–‡ä»¶å·²å­˜åœ¨ä½†æ— æ³•éªŒè¯å®Œæ•´æ€§: {file_name} å³å°†é‡æ–°ä¸‹è½½\")\n",
    "                    os.remove(full_path)\n",
    "                    \n",
    "        \n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            for attempt in range(retries):\n",
    "                try:\n",
    "                    # æ¯æ¬¡é‡è¯•éƒ½é‡æ–°è·å–çŠ¶æ€\n",
    "                    downloaded_size = 0\n",
    "                    if os.path.exists(temp_path):\n",
    "                        downloaded_size = os.path.getsize(temp_path)\n",
    "                        tqdm.write(f\"å‘ç°éƒ¨åˆ†ä¸‹è½½æ–‡ä»¶: {file_name} (å·²ä¸‹è½½: {downloaded_size} bytes)\")\n",
    "                    \n",
    "                    total_size = 0\n",
    "                    accept_ranges = \"none\"\n",
    "                    \n",
    "                    # è·å–æœåŠ¡å™¨æ–‡ä»¶ä¿¡æ¯\n",
    "                    async with session.head(\n",
    "                        source.download_url,\n",
    "                        timeout=aiohttp.ClientTimeout(total=10)\n",
    "                    ) as head_response:\n",
    "                        head_response.raise_for_status()\n",
    "                        total_size = int(head_response.headers.get('content-length', 0))\n",
    "                        accept_ranges = head_response.headers.get('Accept-Ranges', 'none').lower()\n",
    "                        last_modified = head_response.headers.get('Last-Modified', '')\n",
    "                        etag = head_response.headers.get('ETag', '')\n",
    "                    \n",
    "                    # æ£€æŸ¥æ–‡ä»¶å®Œæ•´æ€§\n",
    "                    if downloaded_size > 0:\n",
    "                        if total_size > 0 and downloaded_size >= total_size:\n",
    "                            # ä¿®å¤2: ç¡®ä¿é‡å‘½åååˆ é™¤ä¸´æ—¶æ–‡ä»¶\n",
    "                            os.rename(temp_path, full_path)\n",
    "                            if os.path.exists(temp_path + \".meta\"):\n",
    "                                os.remove(temp_path + \".meta\")\n",
    "                            return {\n",
    "                                \"success\": True,\n",
    "                                \"file_name\": file_name,\n",
    "                                \"file_size\": downloaded_size,\n",
    "                                \"message\": f\"æ–‡ä»¶å·²å®Œæ•´: {file_name}\"\n",
    "                            }\n",
    "                        \n",
    "                        # éªŒè¯æ–‡ä»¶å…ƒæ•°æ®æ˜¯å¦åŒ¹é…\n",
    "                        if os.path.exists(temp_path + \".meta\"):\n",
    "                            with open(temp_path + \".meta\", \"r\") as meta_file:\n",
    "                                saved_meta = json.load(meta_file)\n",
    "                                if saved_meta.get('size') != total_size or \\\n",
    "                                saved_meta.get('etag') != etag or \\\n",
    "                                saved_meta.get('last_modified') != last_modified:\n",
    "                                    tqdm.write(\"æ–‡ä»¶å…ƒæ•°æ®å·²å˜æ›´ï¼Œé‡æ–°ä¸‹è½½\")\n",
    "                                    os.remove(temp_path)\n",
    "                                    os.remove(temp_path + \".meta\")\n",
    "                                    downloaded_size = 0\n",
    "                    \n",
    "                    # å‡†å¤‡Rangeè¯·æ±‚\n",
    "                    headers = {}\n",
    "                    if downloaded_size > 0 and accept_ranges == 'bytes':\n",
    "                        headers = {'Range': f'bytes={downloaded_size}-'}\n",
    "                        if etag:\n",
    "                            headers['If-Range'] = etag\n",
    "                        elif last_modified:\n",
    "                            headers['If-Range'] = last_modified\n",
    "                    \n",
    "                    # æ‰§è¡Œä¸‹è½½\n",
    "                    async with session.get(\n",
    "                        source.download_url, \n",
    "                        timeout=aiohttp.ClientTimeout(total=180),\n",
    "                        headers=headers,\n",
    "                        raise_for_status=True\n",
    "                    ) as response:\n",
    "                        if response.status == 206:\n",
    "                            content_range = response.headers.get('Content-Range', '')\n",
    "                            if 'bytes' in content_range and '/' in content_range:\n",
    "                                total_size = int(content_range.split('/')[-1])\n",
    "                        \n",
    "                        elif response.status == 200 and downloaded_size > 0:\n",
    "                            tqdm.write(\"æœåŠ¡å™¨å¿½ç•¥Rangeè¯·æ±‚ï¼Œé‡æ–°ä¸‹è½½å®Œæ•´æ–‡ä»¶\")\n",
    "                            if os.path.exists(temp_path):\n",
    "                                os.remove(temp_path)\n",
    "                            downloaded_size = 0\n",
    "                        \n",
    "                        # åˆ›å»ºè¿›åº¦æ¡\n",
    "                        with tqdm(\n",
    "                            total=total_size if total_size > 0 else None,\n",
    "                            unit='B', \n",
    "                            unit_scale=True,\n",
    "                            desc=f\"ä¸‹è½½ {file_name[:30]}\",\n",
    "                            unit_divisor=1024,\n",
    "                            miniters=1,\n",
    "                            mininterval=0.1,\n",
    "                            ascii=True,\n",
    "                            dynamic_ncols=True,\n",
    "                            position=position,\n",
    "                            leave=False,\n",
    "                            initial=downloaded_size,\n",
    "                            bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]'\n",
    "                        ) as progress_bar:\n",
    "                            # ä¿å­˜å…ƒæ•°æ®\n",
    "                            if attempt == 0 and (etag or last_modified):\n",
    "                                with open(temp_path + \".meta\", \"w\") as meta_file:\n",
    "                                    json.dump({\n",
    "                                        'size': total_size,\n",
    "                                        'etag': etag,\n",
    "                                        'last_modified': last_modified\n",
    "                                    }, meta_file)\n",
    "                            \n",
    "                            # å†™å…¥æ–‡ä»¶\n",
    "                            async with aiofiles.open(temp_path, 'ab' if downloaded_size > 0 else 'wb') as file:\n",
    "                                async for chunk in response.content.iter_chunked(65536):\n",
    "                                    await file.write(chunk)\n",
    "                                    progress_bar.update(len(chunk))\n",
    "                        \n",
    "                        # ä¸‹è½½å®Œæˆåå¤„ç†\n",
    "                        final_size = os.path.getsize(temp_path)\n",
    "                        \n",
    "                        # ä¿®å¤3: ç¡®ä¿é‡å‘½åååˆ é™¤ä¸´æ—¶æ–‡ä»¶\n",
    "                        os.rename(temp_path, full_path)\n",
    "                        \n",
    "                        # æ¸…ç†å…ƒæ•°æ®æ–‡ä»¶\n",
    "                        if os.path.exists(temp_path + \".meta\"):\n",
    "                            os.remove(temp_path + \".meta\")\n",
    "                        \n",
    "                        # éªŒè¯æ–‡ä»¶å¤§å°\n",
    "                        if total_size > 0 and final_size != total_size:\n",
    "                            tqdm.write(f\"æ–‡ä»¶å¤§å°ä¸åŒ¹é… ({final_size} vs {total_size})\")\n",
    "                            if os.path.exists(full_path):\n",
    "                                os.remove(full_path)\n",
    "                            if attempt < retries - 1:\n",
    "                                tqdm.write(f\"é‡è¯•ä¸‹è½½ ({attempt+1}/{retries})\")\n",
    "                                continue\n",
    "                        \n",
    "                        return {\n",
    "                            \"success\": True,\n",
    "                            \"file_name\": file_name,\n",
    "                            \"file_size\": final_size,\n",
    "                            \"message\": f\"ä¸‹è½½å®Œæˆ: {file_name}\"\n",
    "                        }\n",
    "                    \n",
    "                except (aiohttp.ClientError, asyncio.TimeoutError) as e:\n",
    "                    current_size = os.path.getsize(temp_path) if os.path.exists(temp_path) else 0\n",
    "                    \n",
    "                    if attempt < retries - 1:\n",
    "                        wait_time = min(2 ** attempt, 30)\n",
    "                        tqdm.write(f\"ä¸‹è½½å¤±è´¥ ({attempt+1}/{retries}), {wait_time}ç§’åé‡è¯•: {str(e)}\")\n",
    "                        tqdm.write(f\"å·²ä¸‹è½½: {current_size} bytes\")\n",
    "                        await asyncio.sleep(wait_time)\n",
    "                    else:\n",
    "                        # ä¿®å¤4: å¤±è´¥æ—¶æ¸…ç†ä¸´æ—¶å…ƒæ•°æ®æ–‡ä»¶\n",
    "                        if os.path.exists(temp_path + \".meta\"):\n",
    "                            os.remove(temp_path + \".meta\")\n",
    "                        return {\n",
    "                            \"success\": False,\n",
    "                            \"file_name\": file_name,\n",
    "                            \"error\": str(e),\n",
    "                            \"message\": f\"ä¸‹è½½å¤±è´¥: {file_name}\"\n",
    "                        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "012099a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class HanimeDownloadManage:\n",
    "    def __init__(self, url, download_root_dir='./download'):\n",
    "        self.url = url\n",
    "        self._download_root_dir = download_root_dir\n",
    "        self.title = None\n",
    "        self._download_dir = None\n",
    "        self.player_list = []\n",
    "        self.headers = {\n",
    "                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36',\n",
    "                'Referer': 'https://hanime1.me/'\n",
    "            }\n",
    "        self.scraper = cloudscraper.create_scraper(\n",
    "                browser={\n",
    "                    'browser': 'chrome',\n",
    "                    'platform': 'windows',\n",
    "                    'desktop': True\n",
    "                }\n",
    "            )\n",
    "    \n",
    "    def __str__(self):\n",
    "        \"\"\"è¿”å›æ ¼å¼åŒ–çš„è§†é¢‘ä¿¡æ¯\"\"\"\n",
    "        head_title = f\"{'='*(54-len(self.title)//2)}â¤{self.title}â¤{'='*(54-len(self.title)//2)}\\n\" \n",
    "        info_list = [head_title]\n",
    "        for index, video in enumerate(self.player_list, 1):\n",
    "            # æ ‡é¢˜éƒ¨åˆ†\n",
    "            title_str = f\"{index}. ğŸ“º è§†é¢‘æ ‡é¢˜: {video.title}\\t\"\n",
    "            \n",
    "            # åŸå§‹é“¾æ¥\n",
    "            url_str = f\"ğŸŒ åŸå§‹é“¾æ¥: {video.url}\\n\"\n",
    "            \n",
    "            # ä¸‹è½½æºéƒ¨åˆ†\n",
    "            sources_str = \"\"\n",
    "            if video.sources:\n",
    "                sources_str = \"\\tğŸ“¥ å¯ç”¨ä¸‹è½½æº:\\n\"\n",
    "                \n",
    "                # ä¸ºæ¯ä¸ªä¸‹è½½æºæ·»åŠ åºå·å’Œæ ¼å¼åŒ–çš„ä¿¡æ¯\n",
    "                for i, source in enumerate(video.sources, 1):\n",
    "                    sources_str += f\"\\t\\tğŸ”¢ æº {i}: {\"ğŸ† æ¨è\" if i == 1 else \"\" }\\n\\t\\t\\turl: {source.download_url}\\n\\t\\t\\tfile type: {source.suffix}\\n\\t\\t\\tresolution: {source.clarity}p\\n\"\n",
    "            else:\n",
    "                sources_str = \"\\t\\tâš ï¸ æ— å¯ç”¨ä¸‹è½½æº\\n\"\n",
    "\n",
    "            info_list.append(''.join([title_str, url_str, sources_str]))\n",
    "        return '\\n'.join(info_list)\n",
    "\n",
    "    @property\n",
    "    def download_dir(self):\n",
    "        if self._download_dir is not None:\n",
    "            return self._download_dir\n",
    "        else:\n",
    "            if self.title is None:\n",
    "                return None\n",
    "            else:\n",
    "                self._download_dir = os.path.join(self._download_root_dir, self.title)\n",
    "                return self._download_dir\n",
    "\n",
    "    def update(self):\n",
    "        # å‘é€è¯·æ±‚\n",
    "        response = self.scraper.get(self.url, headers=self.headers, timeout=20)\n",
    "        response.raise_for_status()  # æ£€æŸ¥HTTPé”™è¯¯\n",
    "\n",
    "        # è§£æHTML\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # è§£ææ ‡é¢˜\n",
    "        title = soup.select_one('#video-playlist-wrapper > div.single-icon-wrapper.video-playlist-top > h4:nth-child(1)')\n",
    "        if title:\n",
    "            self.title = title.get_text(strip=True)\n",
    "\n",
    "        # æŸ¥æ‰¾æ’­æ”¾åˆ—è¡¨ï¼ˆè¿”å›ç¬¬ä¸€ä¸ªåŒ¹é…é¡¹ï¼‰\n",
    "        playlist_scroll = soup.select_one('#playlist-scroll')\n",
    "        if playlist_scroll:\n",
    "            target_elements = playlist_scroll.find_all('div', recursive=False)\n",
    "            \n",
    "            for element in target_elements:\n",
    "                # æå–æ‰€éœ€ä¿¡æ¯\n",
    "                href = element.select_one('a.overlay')['href'],    # href å±æ€§\n",
    "\n",
    "                title = element.select_one('div.card-mobile-title').get_text(strip=True)  # title å±æ€§\n",
    "                self.player_list.append(Video(title=title, url=href[0]))\n",
    "                \n",
    "            self.player_list.reverse()\n",
    "        if len(self.player_list) > 0:\n",
    "            self._update_download_link()\n",
    "        print(self)\n",
    "\n",
    "    def _update_download_link(self):\n",
    "        for video in self.player_list:\n",
    "            # å‘é€è¯·æ±‚\n",
    "            response = self.scraper.get(video.url, headers=self.headers, timeout=20)\n",
    "            response.raise_for_status()  # æ£€æŸ¥HTTPé”™è¯¯\n",
    "            # è§£æHTML\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            plyr_list = soup.select('#player > source')\n",
    "\n",
    "            for source in plyr_list:\n",
    "                src = source.get('src')\n",
    "                parts = source.get('type').split('/', 1)\n",
    "                suffix = parts[1] if len(parts) > 1 else \"\"\n",
    "                size = int(source.get('size'))\n",
    "                video.add_download_link(DownloadLink(download_url=src, suffix=suffix, clarity=size))\n",
    "            # æŒ‰ clarity é™åºæ’åº\n",
    "            video.sources.sort(key=lambda x: x.clarity, reverse=True)\n",
    "\n",
    "    def download(self):\n",
    "        for video in self.player_list:\n",
    "            video.download(self.download_dir)\n",
    "        return None\n",
    "\n",
    "    async def download_async(self, max_concurrent=2):\n",
    "        \"\"\"æ‰¹é‡ä¸‹è½½é˜Ÿåˆ—ä¸­çš„æ‰€æœ‰è§†é¢‘ï¼Œæ§åˆ¶å¹¶å‘æ•°\"\"\"\n",
    "        # åˆ›å»ºä¿¡å·é‡æ§åˆ¶å¹¶å‘æ•°é‡\n",
    "        semaphore = asyncio.Semaphore(max_concurrent)\n",
    "\n",
    "        # åœ¨ä¸‹è½½ç®¡ç†å™¨ä¸­æ·»åŠ é”\n",
    "        async def download_with_position(video, position):\n",
    "            async with semaphore:\n",
    "                # ä½¿ç”¨positionç¡®ä¿åœ¨ä»»åŠ¡å¼€å§‹å‰è¾“å‡ºä¿¡æ¯ä¸ä¼šæ··ä¹±\n",
    "                await video.download_async(self.download_dir, position=position)\n",
    "                \n",
    "        # åˆ›å»ºæ‰€æœ‰ä¸‹è½½ä»»åŠ¡çš„åç¨‹åˆ—è¡¨å¹¶åˆ†é…ä½ç½®\n",
    "        tasks = [\n",
    "            download_with_position(video, index)\n",
    "            for index, video in enumerate(self.player_list)\n",
    "        ]\n",
    "        \n",
    "        # è¿è¡Œæ‰€æœ‰ä»»åŠ¡\n",
    "        results = await asyncio.gather(*tasks, return_exceptions=True)\n",
    "        \n",
    "        for index, result in enumerate(results):\n",
    "            if isinstance(result, Exception):\n",
    "                print(f\"æ–‡ä»¶ {self.player_list[index].title} ä¸‹è½½å¤±è´¥: {result}\")\n",
    "            else:\n",
    "                print(f\"æ–‡ä»¶ {self.player_list[index].title} ä¸‹è½½æˆåŠŸï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79583c90",
   "metadata": {},
   "source": [
    "å°†urlæ›¿æ¢ä¸ºä½ è¦ä¸‹è½½çš„è§†é¢‘é“¾æ¥ï¼Œè¿è¡Œåå³å¯å¼€å§‹ä¸‹è½½è¯¥è§†é¢‘ä»¥åŠåŒç³»åˆ—ä¸‹çš„æ‰€æœ‰è§†é¢‘ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "969c461b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================â¤OVAãƒˆãƒŠãƒªãƒã‚«ãƒã‚¸ãƒ§ + OVAãƒ¨ã‚´ãƒ¬ã‚¿ã‚«ãƒã‚¸ãƒ§â¤==========================================\n",
      "\n",
      "1. ğŸ“º è§†é¢‘æ ‡é¢˜: ä½åœ¨éš”å£çš„å¥¹\tğŸŒ åŸå§‹é“¾æ¥: https://hanime1.me/watch?v=109872\n",
      "\tğŸ“¥ å¯ç”¨ä¸‹è½½æº:\n",
      "\t\tğŸ”¢ æº 1: ğŸ† æ¨è\n",
      "\t\t\turl: https://vdownload.hembed.com/109872-1080p.mp4?secure=LfR2PAAsjLs0u8X6y6czNg==,1751295854\n",
      "\t\t\tfile type: mp4\n",
      "\t\t\tresolution: 1080p\n",
      "\t\tğŸ”¢ æº 2: \n",
      "\t\t\turl: https://vdownload.hembed.com/109872-720p.mp4?secure=6Wg4NfwX9oV9X_l-oreDUA==,1751295854\n",
      "\t\t\tfile type: mp4\n",
      "\t\t\tresolution: 720p\n",
      "\t\tğŸ”¢ æº 3: \n",
      "\t\t\turl: https://vdownload.hembed.com/109872-480p.mp4?secure=s90jz9TIlqZAN3luW1FSkA==,1751295854\n",
      "\t\t\tfile type: mp4\n",
      "\t\t\tresolution: 480p\n",
      "\n",
      "2. ğŸ“º è§†é¢‘æ ‡é¢˜: è¢«ç·æ±¡çš„å¥¹\tğŸŒ åŸå§‹é“¾æ¥: https://hanime1.me/watch?v=109873\n",
      "\tğŸ“¥ å¯ç”¨ä¸‹è½½æº:\n",
      "\t\tğŸ”¢ æº 1: ğŸ† æ¨è\n",
      "\t\t\turl: https://vdownload.hembed.com/109873-1080p.mp4?secure=JIE4p2zHNhbT9IWO99ZTBg==,1751295854\n",
      "\t\t\tfile type: mp4\n",
      "\t\t\tresolution: 1080p\n",
      "\t\tğŸ”¢ æº 2: \n",
      "\t\t\turl: https://vdownload.hembed.com/109873-720p.mp4?secure=UAS-qGatZUfkb_13Px3UnQ==,1751295854\n",
      "\t\t\tfile type: mp4\n",
      "\t\t\tresolution: 720p\n",
      "\t\tğŸ”¢ æº 3: \n",
      "\t\t\turl: https://vdownload.hembed.com/109873-480p.mp4?secure=OyjJFWqGd9w00Yk67lidIA==,1751295854\n",
      "\t\t\tfile type: mp4\n",
      "\t\t\tresolution: 480p\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hdm = HanimeDownloadManage('https://hanime1.me/watch?v=109872')\n",
    "hdm.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752b74e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "await hdm.download_async()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
